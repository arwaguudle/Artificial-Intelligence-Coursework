{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1.lOADING THE DATA ---\n",
    "#Adjust the paths to match where you've unzipped \"UCI HAR Dataset\"\n",
    "\n",
    "PATH = \"/Users/ahmed/Desktop/Artificial-Intelligence-Coursework/UCI HAR Dataset\"\n",
    "\n",
    "features_path = PATH + \"/features.txt\"\n",
    "activity_labels_path = PATH + \"/activity_labels.txt\"\n",
    "X_train_path = PATH + \"/train/X_train.txt\"\n",
    "y_train_path = PATH + \"/train/y_train.txt\"\n",
    "X_test_path = PATH + \"/test/X_test.txt\"\n",
    "y_test_path = PATH + \"/test/y_test.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature names, This appends the column index to any duplicate names.\n",
    "\n",
    "features_df = pd.read_csv(features_path, sep=\"\\s+\", header=None, names=[\"idx\", \"feature\"])\n",
    "feature_names = features_df[\"feature\"].tolist()\n",
    "\n",
    "\n",
    "# his appends the column index to any duplicate names.\n",
    "features_df[\"feature\"] = features_df[\"feature\"].astype(str) + \"_\" + features_df.index.astype(str)\n",
    "feature_names = features_df[\"feature\"].tolist()\n",
    "\n",
    "\n",
    "# Load activity labels (mapping IDs 1-6 to string names)\n",
    "activity_labels_df = pd.read_csv(activity_labels_path, sep=\"\\s+\", header=None, names=[\"id\", \"activity\"])\n",
    "activity_map = dict(zip(activity_labels_df[\"id\"], activity_labels_df[\"activity\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the training data\n",
    "X_train = pd.read_csv(X_train_path, sep=\"\\s+\", header=None, names=feature_names)\n",
    "y_train = pd.read_csv(y_train_path, sep=\"\\s+\", header=None, names=[\"activity\"])\n",
    "X_test = pd.read_csv(X_test_path, sep=\"\\s+\", header=None, names=feature_names)\n",
    "y_test = pd.read_csv(y_test_path, sep=\"\\s+\", header=None, names=[\"activity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map activity IDs to their names\n",
    "y_train[\"activity\"] = y_train[\"activity\"].map(activity_map)\n",
    "y_test[\"activity\"] = y_test[\"activity\"].map(activity_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ---2.CONVERT MULTI-CLASS LABELS TO BINARY ---\n",
    "def to_binary_label(activity):\n",
    "    if activity in [\"WALKING\", \"WALKING_UPSTAIRS\", \"WALKING_DOWNSTAIRS\"]:\n",
    "        return 1 #Active\n",
    "    else:\n",
    "        return 0 #Inactive\n",
    "    \n",
    "y_train_binary = y_train[\"activity\"].apply(to_binary_label)\n",
    "y_test_binary = y_test[\"activity\"].apply(to_binary_label)\n",
    "\n",
    "\n",
    "y_train_binary = y_train_binary.astype(int).values.ravel()\n",
    "y_test_binary = y_test_binary.astype(int).values.ravel()\n",
    "#Now we have 0/1 labels in y_train[\"Binary\"] and y_test[\"Binary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduction of the number of features\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"pca\", PCA(n_components=50)), #reduce from 561 -> 50 \n",
    "    (\"svm\", SVC(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "#can tweak n components depending on how much dimension reduction you want vs how much#\n",
    "#computational time you can spare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 1.00\n",
      "Precision: 1.00\n",
      "Recall: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pipeline.fit(X_train, y_train_binary)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test_binary, y_pred)\n",
    "precision = precision_score(y_test_binary, y_pred)\n",
    "recall = recall_score(y_test_binary, y_pred)\n",
    "\n",
    "print(\"F1 Score: {:.2f}\".format(f1))\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the baseline svm models with different kernels (linear, polynomial, rbf)\n",
    "param_grid = [\n",
    "    {\n",
    "        \"svm__kernel\": [\"linear\"],\n",
    "        \"svm__C\": [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        \"svm__kernel\": [\"poly\"],\n",
    "        \"svm__degree\": [2, 3, 4],\n",
    "        \"svm__gamma\": [0.1, 1],\n",
    "        \"svm__C\": [0.1, 1, 10]\n",
    "    },\n",
    "    {\n",
    "        \"svm__kernel\": [\"rbf\"],\n",
    "        \"svm__C\": [0.1, 1, 10],\n",
    "        \"svm__gamma\": [0.1, 1]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Best parameters:  {'svm__C': 10, 'svm__kernel': 'linear'}\n",
      "Best score:  0.8974447192177566\n"
     ]
    }
   ],
   "source": [
    "#grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train.values.ravel())\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters:  {'svm__kernel': 'poly', 'svm__gamma': 0.1, 'svm__degree': 3, 'svm__C': 10}\n",
      "Best score:  0.8892828971653941\n"
     ]
    }
   ],
   "source": [
    "#it took too long, so we are going do a RandomizedSearchCV instead\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=10,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train.values.ravel())\n",
    "print(\"Best parameters: \", random_search.best_params_)\n",
    "print(\"Best score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[32m      2\u001b[39m y_pred = grid_search.best_estimator_.predict(X_test)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:2674\u001b[39m, in \u001b[36mclassification_report\u001b[39m\u001b[34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[39m\n\u001b[32m   2671\u001b[39m y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     labels = \u001b[43munique_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2675\u001b[39m     labels_given = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\utils\\multiclass.py:117\u001b[39m, in \u001b[36munique_labels\u001b[39m\u001b[34m(*ys)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;66;03m# Check that we don't mix string type with number type\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(label, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m ys_labels)) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMix of label input types (string and number)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m xp.asarray(\u001b[38;5;28msorted\u001b[39m(ys_labels))\n",
      "\u001b[31mValueError\u001b[39m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from  sklearn.metrics import classification_report\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(classification_report(y_test_binary, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
